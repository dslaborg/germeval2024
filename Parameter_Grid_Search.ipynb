{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4914ad1e-766c-42de-a921-ab48aed369c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e8e16fa-bb7a-4827-acb4-5c516203c87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d5c3cb4-5baf-404a-89b7-ce1c4552f90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch version: 2.1.2+cu118\n",
      "cuda available: True\n",
      "devices count: 4\n"
     ]
    }
   ],
   "source": [
    "print(f\"pytorch version: {torch.__version__}\")\n",
    "print(f\"cuda available: {torch.cuda.is_available()}\")\n",
    "print(f\"devices count: {torch.cuda.device_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af2559ac-5aea-4f76-bd10-7f08794c76d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Needed for MLP\n",
    "def balance_dataset(X, y): \n",
    "    value_counts = []\n",
    "    for i in range(5):\n",
    "        value_counts.append(y.count(i))\n",
    "    index = 0\n",
    "    added = {1: 0, 2: 0, 3: 0, 4: 0}\n",
    "    add_to_y = {1: [], 2: [], 3: [], 4: []}\n",
    "    add_to_X = {1: [], 2: [], 3: [], 4: []}\n",
    "    while sum(added.values()) + sum(value_counts) < 5 * value_counts[0]:\n",
    "        if index >= len(y):\n",
    "            index = 0\n",
    "        if y[index] != 0 and added[y[index]] + value_counts[y[index]] < value_counts[0]:\n",
    "            add_to_y[y[index]].append(y[index])\n",
    "            add_to_X[y[index]].append(X[index])\n",
    "            added[y[index]] += 1\n",
    "        index += 1\n",
    "    new_X = X.copy()\n",
    "    new_y = y.copy()\n",
    "    index = 0\n",
    "    while index < sum(added.values()):\n",
    "        for i in range(1, 5):\n",
    "            if len(add_to_y[i]) > 0:\n",
    "                new_y.append(add_to_y[i].pop(0))\n",
    "                new_X.append(add_to_X[i].pop(0))\n",
    "                index += 1\n",
    "    return new_X, new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d63ebfad-0336-43e6-ba71-fdf81c3e9082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedJsonLInputFile(model, path):\n",
    "    input = pd.read_json(path, lines=True).set_index('id')\n",
    "    e = pd.DataFrame(index=input.index, columns=['Embedding'])\n",
    "    for idx in tqdm(input.index):\n",
    "        sentence = input.loc[idx]['text']\n",
    "        e.loc[idx]['Embedding'] = model.encode(sentence)\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "856cd7d2-2205-4522-96b3-1ab06c9188e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_st1(predictions):\n",
    "    #list with columns [\"id\": ..., \"A001\": \"1.0, \"A002\": 0.0, \"A003\": ..., ..., \"A012\": ...] \n",
    "    QUANT_TO_QUAL={0: 0, 1: 1, 2: 1, 3: 1, 4: 1}\n",
    "    NUMBER_TO_LABEL={0: \"0-Kein\", 1: \"1-Gering\", 2: \"2-Vorhanden\", 3: \"3-Stark\", 4: \"4-Extrem\"}\n",
    "    \n",
    "    #predictions_quant: pd.DataFrame = predictions.applymap(lambda x: LABEL_VALS_QUANT[x] if not pd.isna(x) else x)\n",
    "    predictions_qual: pd.DataFrame = predictions.applymap(lambda x: QUANT_TO_QUAL[x] if not pd.isna(x) else x)\n",
    "    \n",
    "    output = pd.DataFrame(index=[\"id\"])\n",
    "    output.index = predictions.index\n",
    "    \n",
    "    #create expected columns\n",
    "    output[\"bin_maj\"] = predictions_qual.mode(axis='columns')[0]\n",
    "    output[\"bin_one\"] = predictions_qual.apply(lambda x: (x == 1).any(), axis='columns')\n",
    "    output[\"bin_all\"] = predictions_qual.apply(lambda x: not (x == 0).any(), axis='columns')\n",
    "    output[\"multi_maj\"] = predictions.mode(axis='columns')[0].apply(lambda x: NUMBER_TO_LABEL[x])\n",
    "    output[\"disagree_bin\"] = output.apply(lambda x: x[\"bin_one\"] and not x[\"bin_all\"], axis='columns')\n",
    "    \n",
    "    #convert False/True to 0/1\n",
    "    output['bin_maj'] = output['bin_maj'].apply(lambda x: 1 if x else 0)\n",
    "    output['bin_one'] = output['bin_one'].apply(lambda x: 1 if x else 0)\n",
    "    output['bin_all'] = output['bin_all'].apply(lambda x: 1 if x else 0)\n",
    "    output['disagree_bin'] = output['disagree_bin'].apply(lambda x: 1 if x else 0)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e04453c-a67a-4bad-ba49-02d4efc7fc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedders = [\n",
    "    #{'model': 'intfloat/multilingual-e5-small', 'model_ident': 'me5-small'},\n",
    "    #{'model': 'intfloat/multilingual-e5-base', 'model_ident': 'me5-base'},\n",
    "    {'model': 'intfloat/multilingual-e5-large', 'model_ident': 'me5-large'},\n",
    "    {'model': 'deutsche-telekom/gbert-large-paraphrase-cosine', 'model_ident': 't-gbert-lpc'}\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    {\n",
    "        'model': SVC(kernel='rbf', C=5, class_weight=\"balanced\", random_state=SEED), \n",
    "        'model_ident': 'svc', \n",
    "        'prerun': None,\n",
    "        'param_grid': {'C': [1, 2, 5, 8, 13, 21, 35, 56, 91]}\n",
    "    }, {\n",
    "        'model': RandomForestClassifier(class_weight=\"balanced\", criterion=\"gini\", random_state=SEED), \n",
    "        'model_ident': 'rfc', \n",
    "        'prerun': None,\n",
    "        'param_grid': {'max_depth': [1, 2, 5, 8, 13, 21, 35, 56, 91], 'n_estimators': [10, 20, 50, 80, 130, 210, 350, 560]}\n",
    "    }, {\n",
    "        'model': MLPClassifier(early_stopping=True, n_iter_no_change=10, random_state=SEED, max_iter=1000), \n",
    "        'model_ident': 'mlp', \n",
    "        'prerun': balance_dataset,\n",
    "        'param_grid': {'hidden_layer_sizes': [(64,), (128,), (256,), (512,), (1024,), (1536,), (2048,)]}\n",
    "    }\n",
    "]\n",
    "\n",
    "annotators = [\"A001\", \"A002\", \"A003\", \"A004\", \"A005\", \"A007\", \"A008\", \"A009\", \"A010\", \"A012\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26798741-0cc6-4148-96eb-2661d2886f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Model: me5-large\n",
      "Classification Model: svc\n",
      "Annotator: A001\n",
      "{'C': 2}\n",
      "0.54\n",
      "Annotator: A002\n",
      "{'C': 91}\n",
      "0.7091666666666666\n",
      "Annotator: A003\n",
      "{'C': 13}\n",
      "0.6209677419354839\n",
      "Annotator: A004\n",
      "{'C': 21}\n",
      "0.6513409961685823\n",
      "Annotator: A005\n",
      "{'C': 13}\n",
      "0.5859872611464968\n",
      "Annotator: A007\n",
      "{'C': 21}\n",
      "0.5938697318007663\n",
      "Annotator: A008\n",
      "{'C': 91}\n",
      "0.6843501326259946\n",
      "Annotator: A009\n",
      "{'C': 56}\n",
      "0.596551724137931\n",
      "Annotator: A010\n",
      "{'C': 91}\n",
      "0.62\n",
      "Annotator: A012\n",
      "{'C': 91}\n",
      "0.5966666666666667\n",
      "Classification Model: rfc\n",
      "Annotator: A001\n",
      "{'max_depth': 5, 'n_estimators': 210}\n",
      "0.62\n",
      "Annotator: A002\n",
      "{'max_depth': 13, 'n_estimators': 50}\n",
      "0.7375\n",
      "Annotator: A003\n",
      "{'max_depth': 5, 'n_estimators': 560}\n",
      "0.592741935483871\n",
      "Annotator: A004\n",
      "{'max_depth': 5, 'n_estimators': 210}\n",
      "0.6704980842911877\n",
      "Annotator: A005\n",
      "{'max_depth': 8, 'n_estimators': 130}\n",
      "0.643312101910828\n",
      "Annotator: A007\n",
      "{'max_depth': 8, 'n_estimators': 130}\n",
      "0.6053639846743295\n",
      "Annotator: A008\n",
      "{'max_depth': 5, 'n_estimators': 350}\n",
      "0.7453580901856764\n",
      "Annotator: A009\n",
      "{'hidden_layer_sizes': (2048,)}\n",
      "0.6741666666666667\n",
      "Annotator: A003\n",
      "{'hidden_layer_sizes': (1024,)}\n",
      "0.592741935483871\n",
      "Annotator: A004\n",
      "{'hidden_layer_sizes': (1024,)}\n",
      "0.578544061302682\n",
      "Annotator: A008\n",
      "{'hidden_layer_sizes': (2048,)}\n",
      "0.6604774535809018\n",
      "Annotator: A009\n",
      "{'hidden_layer_sizes': (1024,)}\n",
      "0.5724137931034483\n",
      "Annotator: A010\n",
      "{'hidden_layer_sizes': (2048,)}\n",
      "0.5983333333333334\n",
      "Annotator: A012\n",
      "{'hidden_layer_sizes': (1536,)}\n",
      "0.5741666666666667\n",
      "Embedding Model: t-gbert-lpc\n",
      "Classification Model: svc\n",
      "Annotator: A001\n",
      "{'C': 5}\n",
      "0.615\n",
      "Annotator: A002\n",
      "{'C': 35}\n",
      "0.7308333333333333\n",
      "Annotator: A003\n",
      "{'C': 2}\n",
      "0.6411290322580645\n",
      "Annotator: A004\n",
      "{'C': 13}\n",
      "0.6743295019157088\n",
      "Annotator: A005\n",
      "{'C': 5}\n",
      "0.6496815286624203\n",
      "Annotator: A007\n",
      "{'C': 5}\n",
      "0.6360153256704981\n",
      "Annotator: A008\n",
      "{'C': 21}\n",
      "0.7400530503978779\n",
      "Annotator: A009\n",
      "{'C': 35}\n",
      "0.653448275862069\n",
      "Annotator: A010\n",
      "{'C': 13}\n",
      "0.6625\n",
      "Annotator: A012\n",
      "{'C': 13}\n",
      "0.6066666666666667\n",
      "Classification Model: rfc\n",
      "Annotator: A001\n",
      "{'max_depth': 5, 'n_estimators': 350}\n",
      "0.645\n",
      "Annotator: A002\n",
      "{'max_depth': 21, 'n_estimators': 50}\n",
      "0.7375\n",
      "Annotator: A003\n",
      "{'max_depth': 5, 'n_estimators': 560}\n",
      "0.5967741935483871\n",
      "Annotator: A004\n",
      "{'max_depth': 8, 'n_estimators': 350}\n",
      "0.6666666666666666\n",
      "Annotator: A005\n",
      "{'max_depth': 8, 'n_estimators': 560}\n",
      "0.6624203821656051\n",
      "Annotator: A007\n",
      "{'max_depth': 8, 'n_estimators': 560}\n",
      "0.6130268199233716\n",
      "Annotator: A008\n",
      "{'max_depth': 8, 'n_estimators': 130}\n",
      "0.7506631299734748\n",
      "Annotator: A009\n",
      "{'max_depth': 21, 'n_estimators': 130}\n",
      "0.6672413793103448\n",
      "Annotator: A010\n",
      "{'max_depth': 13, 'n_estimators': 560}\n",
      "0.6441666666666667\n",
      "Annotator: A012\n",
      "{'max_depth': 13, 'n_estimators': 350}\n",
      "0.6033333333333334\n",
      "Classification Model: mlp\n",
      "Annotator: A001\n",
      "{'hidden_layer_sizes': (1024,)}\n",
      "0.595\n",
      "Annotator: A002\n",
      "{'hidden_layer_sizes': (1536,)}\n",
      "0.6991666666666667\n",
      "Annotator: A003\n",
      "{'hidden_layer_sizes': (1024,)}\n",
      "0.5846774193548387\n",
      "Annotator: A004\n",
      "{'hidden_layer_sizes': (1536,)}\n",
      "0.6360153256704981\n",
      "Annotator: A005\n",
      "{'hidden_layer_sizes': (1536,)}\n",
      "0.6050955414012739\n",
      "Annotator: A007\n",
      "{'hidden_layer_sizes': (2048,)}\n",
      "0.5708812260536399\n",
      "Annotator: A008\n",
      "{'hidden_layer_sizes': (1536,)}\n",
      "0.713527851458886\n",
      "Annotator: A009\n",
      "{'hidden_layer_sizes': (1536,)}\n",
      "0.6293103448275862\n",
      "Annotator: A010\n",
      "{'hidden_layer_sizes': (1536,)}\n",
      "0.6383333333333333\n",
      "Annotator: A012\n",
      "{'hidden_layer_sizes': (512,)}\n",
      "0.5883333333333334\n"
     ]
    }
   ],
   "source": [
    "annotator_model_scores = {}\n",
    "models = {}\n",
    "\n",
    "for embedder in embedders:\n",
    "    print(f\"Embedding Model: {embedder['model_ident']}\")\n",
    "\n",
    "    annotator_model_scores[embedder[\"model_ident\"]] = {}\n",
    "    models[embedder[\"model_ident\"]] = {}\n",
    "    \n",
    "    embeddings = 0\n",
    "    embedding_model = SentenceTransformer(embedder['model'])\n",
    "    \n",
    "    if os.path.isfile(f\"data/embeddings/{embedder['model_ident']}.pkl\"):\n",
    "        embeddings = pd.read_pickle(f\"data/embeddings/{embedder['model_ident']}.pkl\")\n",
    "    else:\n",
    "        embeddings = embedJsonLInputFile(embedding_model, 'data/training/X_all.jsonl')\n",
    "        embeddings.to_pickle(f\"data/embeddings/{embedder['model_ident']}.pkl\")\n",
    "\n",
    "    embedding_dim = len(embeddings.iloc[0])\n",
    "\n",
    "    for classifier in classifiers:\n",
    "        print(f\"Classification Model: {classifier['model_ident']}\")\n",
    "\n",
    "        annotator_model_scores[embedder['model_ident']][classifier['model_ident']] = {}\n",
    "        models[embedder['model_ident']][classifier['model_ident']] = {}\n",
    "\n",
    "        \n",
    "        for annotator in annotators:\n",
    "            score = 0\n",
    "            print(f\"Annotator: {annotator}\")\n",
    "            \n",
    "            y_train = pd.read_json(f\"data/training/y_train_{annotator}.jsonl\", lines=True).set_index('id')\n",
    "            X_train = embeddings.loc[y_train.index]\n",
    "            \n",
    "            y_val = pd.read_json(f\"data/training/y_val_{annotator}.jsonl\", lines=True).set_index('id')\n",
    "            X_val = embeddings.loc[y_val.index]\n",
    "\n",
    "            models[embedder['model_ident']][classifier['model_ident']][annotator] = clone(classifier['model'])\n",
    "            classifier_model = models[embedder['model_ident']][classifier['model_ident']][annotator]\n",
    "\n",
    "            cached = False\n",
    "            with open(f\"data/cache.txt\", 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                for line in lines:\n",
    "                    if line.strip() == f\"{embedder['model_ident']}_{classifier['model_ident']}_{annotator}\":\n",
    "                        cached = True\n",
    "                        break\n",
    "            f.close()\n",
    "            if not cached:\n",
    "                clf = GridSearchCV(classifier_model, classifier['param_grid'], n_jobs=100, cv=5, refit=True)\n",
    "                \n",
    "                X_train_list = X_train['Embedding'].to_list()\n",
    "                y_train_list = y_train[annotator].to_list()\n",
    "    \n",
    "                if classifier[\"prerun\"] is not None:\n",
    "                    X_train_list, y_train_list = classifier[\"prerun\"](X_train_list, y_train_list)\n",
    "    \n",
    "                X_val_list = X_val['Embedding'].to_list()\n",
    "                y_val_list = y_val[annotator].to_list()\n",
    "    \n",
    "                clf.fit(X_train_list, y_train_list)    \n",
    "                print(clf.best_params_)\n",
    "                score = clf.score(X_val_list, y_val_list)\n",
    "\n",
    "                with open(f\"data/models/{embedder['model_ident']}_{classifier['model_ident']}_{annotator}.pkl\", 'w+b') as f:\n",
    "                    pickle.dump(clf.best_estimator_, f)\n",
    "                f.close()\n",
    "                with open(f\"data/cache.txt\", 'a') as f:\n",
    "                    f.write(f\"{embedder['model_ident']}-{classifier['model_ident']}-{annotator}\\n\")\n",
    "                f.close()    \n",
    "            else:\n",
    "                with open(f\"data/models/{embedder['model_ident']}_{classifier['model_ident']}_{annotator}.pkl\", 'rb') as f:\n",
    "                    cached_model = pickle.load(f)\n",
    "                f.close()    \n",
    "                print(f\"Cached: {cached_model}\")\n",
    "                score = cached_model.score(X_val_list, y_val_list)\n",
    "            \n",
    "            print(score)\n",
    "            annotator_model_scores[embedder['model_ident']][classifier['model_ident']][annotator] = score     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bda1424-df54-4ff7-bfb5-9e2ce1e6f391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A001': {'path': 't-gbert-lpc_rfc_A001.pkl', 'embedder': 't-gbert-lpc'},\n",
       " 'A002': {'path': 'me5-large_rfc_A002.pkl', 'embedder': 'me5-large'},\n",
       " 'A003': {'path': 't-gbert-lpc_svc_A003.pkl', 'embedder': 't-gbert-lpc'},\n",
       " 'A004': {'path': 't-gbert-lpc_svc_A004.pkl', 'embedder': 't-gbert-lpc'},\n",
       " 'A005': {'path': 't-gbert-lpc_rfc_A005.pkl', 'embedder': 't-gbert-lpc'},\n",
       " 'A007': {'path': 't-gbert-lpc_svc_A007.pkl', 'embedder': 't-gbert-lpc'},\n",
       " 'A008': {'path': 't-gbert-lpc_rfc_A008.pkl', 'embedder': 't-gbert-lpc'},\n",
       " 'A009': {'path': 't-gbert-lpc_rfc_A009.pkl', 'embedder': 't-gbert-lpc'},\n",
       " 'A010': {'path': 't-gbert-lpc_svc_A010.pkl', 'embedder': 't-gbert-lpc'},\n",
       " 'A012': {'path': 't-gbert-lpc_svc_A012.pkl', 'embedder': 't-gbert-lpc'}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This Cell and the next are a slightly different experiment where using the best model per Annotator is tried\n",
    "\n",
    "annotators_best_score = {\"A001\": 0, \"A002\": 0, \"A003\": 0, \"A004\": 0, \"A005\": 0, \"A007\": 0, \"A008\": 0, \"A009\": 0, \"A010\": 0, \"A012\": 0}\n",
    "annotators_best_model = {\"A001\": {}, \"A002\": {}, \"A003\": {}, \"A004\": {}, \"A005\": {}, \"A007\": {}, \"A008\": {}, \"A009\": {}, \"A010\": {}, \"A012\": {}}\n",
    "\n",
    "for embedder in embedders:\n",
    "    for classifier in classifiers:\n",
    "        for annotator in annotators:\n",
    "            if annotator_model_scores[embedder['model_ident']][classifier['model_ident']][annotator] > annotators_best_score[annotator]:\n",
    "                annotators_best_score[annotator] = annotator_model_scores[embedder['model_ident']][classifier['model_ident']][annotator]\n",
    "                annotators_best_model[annotator]['path'] = f\"{embedder['model_ident']}_{classifier['model_ident']}_{annotator}.pkl\"\n",
    "                annotators_best_model[annotator]['embedder'] = embedder['model_ident']\n",
    "\n",
    "annotators_best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd2c4342-75c5-4978-a689-d7103141f609",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m         predictions_best_models[anno]\u001b[38;5;241m.\u001b[39mloc[idx] \u001b[38;5;241m=\u001b[39m best_classifier_models[anno]\u001b[38;5;241m.\u001b[39mpredict([x])[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     22\u001b[0m output_correct \u001b[38;5;241m=\u001b[39m output_st1(y_val)\n\u001b[0;32m---> 23\u001b[0m output_predicted \u001b[38;5;241m=\u001b[39m output_st1(\u001b[43mpredictions\u001b[49m)\n\u001b[1;32m     24\u001b[0m col_scorings \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m output_correct\u001b[38;5;241m.\u001b[39mcolumns:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "best_classifier_models = {}\n",
    "y_val = pd.read_json(\"data/training/y_val.jsonl\", lines=True).set_index('id')\n",
    "embeddings_all_models = {}\n",
    "predictions_best_models = pd.DataFrame(index=X_val.index, columns=annotators)\n",
    "\n",
    "for embedder in embedders:\n",
    "    embeddings_all_models[embedder['model_ident']] = pd.read_pickle(f\"data/embeddings/{embedder['model_ident']}.pkl\")\n",
    "    X_val = embeddings.loc[y_val.index]\n",
    "\n",
    "for annotator in annotators:\n",
    "    with open(f\"data/models/{annotators_best_model[annotator]['path']}\", 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    best_classifier_models[annotator] = model\n",
    "\n",
    "for idx, _ in y_val.iterrows():\n",
    "    correct_annos = y_val.loc[idx].dropna().index\n",
    "    for anno in correct_annos:\n",
    "        embedder = annotators_best_model[anno]['embedder']\n",
    "        x = embeddings_all_models[embedder].loc[idx]['Embedding']\n",
    "        predictions_best_models[anno].loc[idx] = best_classifier_models[anno].predict([x])[0]\n",
    "    \n",
    "output_correct = output_st1(y_val)\n",
    "output_predicted = output_st1(predictions)\n",
    "col_scorings = []\n",
    "for col in output_correct.columns:\n",
    "    col_scorings.append(f1_score(output_correct[col], output_predicted[col], average='macro'))\n",
    "sum(col_scorings) / len(col_scorings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3fb9db7a-d443-4306-8244-c6437118a1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = pd.read_json(\"data/training/y_val.jsonl\", lines=True).set_index('id')\n",
    "\n",
    "scoring=pd.DataFrame(index = [e['model_ident'] for e in embedders], columns=[c['model_ident'] for c in classifiers])\n",
    "\n",
    "for embedder in embedders:\n",
    "    embeddings = pd.read_pickle(f\"data/embeddings/{embedder['model_ident']}.pkl\")\n",
    "    X_val = embeddings.loc[y_val.index]\n",
    "    \n",
    "    for classifier in classifiers:\n",
    "        \n",
    "        classifier_models = {}\n",
    "        for annotator in annotators:\n",
    "            with open(f\"data/models/{embedder['model_ident']}_{classifier['model_ident']}_{annotator}.pkl\", 'rb') as f:\n",
    "                model = pickle.load(f)\n",
    "            classifier_models[annotator] = model\n",
    "\n",
    "        predictions = pd.DataFrame(index=X_val.index, columns=annotators)\n",
    "        \n",
    "        for idx, row in X_val.iterrows():\n",
    "            correct_annos = y_val.loc[idx].dropna().index\n",
    "            for anno in correct_annos:\n",
    "                predictions[anno].loc[idx] = classifier_models[anno].predict([row['Embedding']])[0]\n",
    "                    \n",
    "        output_correct = output_st1(y_val)\n",
    "        output_predicted = output_st1(predictions)\n",
    "        \n",
    "        col_scorings = []\n",
    "        for col in output_correct.columns:\n",
    "            col_scorings.append(f1_score(output_correct[col], output_predicted[col], average='macro'))\n",
    "        scoring.loc[embedder['model_ident']][classifier['model_ident']] = sum(col_scorings) / len(col_scorings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c79c9e23-8d2f-4b71-8e86-e4676c160fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>svc</th>\n",
       "      <th>rfc</th>\n",
       "      <th>mlp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>me5-large</th>\n",
       "      <td>0.597146</td>\n",
       "      <td>0.418894</td>\n",
       "      <td>0.600716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t-gbert-lpc</th>\n",
       "      <td>0.5717</td>\n",
       "      <td>0.414804</td>\n",
       "      <td>0.592637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  svc       rfc       mlp\n",
       "me5-large    0.597146  0.418894  0.600716\n",
       "t-gbert-lpc    0.5717  0.414804  0.592637"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "scoring.plot(kind=\"bar\")\n",
    "plt.show()\n",
    "scoring"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bp-venv6",
   "language": "python",
   "name": "bp-venv6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
