{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b25e91d6f54da9bf",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "embedders = [\n",
    "    {'model': 'intfloat/multilingual-e5-base', 'model_ident': 'me5-base'},\n",
    "    {'model': 'intfloat/multilingual-e5-large', 'model_ident': 'me5-large'},\n",
    "    {'model': 'deutsche-telekom/gbert-large-paraphrase-cosine', 'model_ident': 't-gbert-lpc'}\n",
    "]\n",
    "\n",
    "classifiers = ['svc', 'rfc', 'mlp']\n",
    "\n",
    "annotators = [\"A001\", \"A002\", \"A003\", \"A004\", \"A005\", \"A007\", \"A008\", \"A009\", \"A010\", \"A012\"]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6bbe18b7b18e002",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def output_st1(predictions):\n",
    "    #list with columns [\"id\": ..., \"A001\": \"1.0, \"A002\": 0.0, \"A003\": ..., ..., \"A012\": ...] \n",
    "    QUANT_TO_QUAL={0: 0, 1: 1, 2: 1, 3: 1, 4: 1}\n",
    "    NUMBER_TO_LABEL={0: \"0-Kein\", 1: \"1-Gering\", 2: \"2-Vorhanden\", 3: \"3-Stark\", 4: \"4-Extrem\"}\n",
    "\n",
    "    #predictions_quant: pd.DataFrame = predictions.applymap(lambda x: LABEL_VALS_QUANT[x] if not pd.isna(x) else x)\n",
    "    predictions_qual: pd.DataFrame = predictions.applymap(lambda x: QUANT_TO_QUAL[x] if not pd.isna(x) else x)\n",
    "\n",
    "    output = pd.DataFrame(index=[\"id\"])\n",
    "    output.index = predictions.index\n",
    "\n",
    "    #create expected columns\n",
    "    output[\"bin_maj\"] = predictions_qual.mode(axis='columns')[0]\n",
    "    output[\"bin_one\"] = predictions_qual.apply(lambda x: (x == 1).any(), axis='columns')\n",
    "    output[\"bin_all\"] = predictions_qual.apply(lambda x: not (x == 0).any(), axis='columns')\n",
    "    output[\"multi_maj\"] = predictions.mode(axis='columns')[0].apply(lambda x: NUMBER_TO_LABEL[x])\n",
    "    output[\"disagree_bin\"] = output.apply(lambda x: x[\"bin_one\"] and not x[\"bin_all\"], axis='columns')\n",
    "\n",
    "    #convert False/True to 0/1\n",
    "    output['bin_maj'] = output['bin_maj'].apply(lambda x: 1 if x else 0)\n",
    "    output['bin_one'] = output['bin_one'].apply(lambda x: 1 if x else 0)\n",
    "    output['bin_all'] = output['bin_all'].apply(lambda x: 1 if x else 0)\n",
    "    output['disagree_bin'] = output['disagree_bin'].apply(lambda x: 1 if x else 0)\n",
    "\n",
    "    return output"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa3371cc70eb1295",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "y_val = pd.read_json(\"created_data/training_data/y_val.jsonl\", lines=True).set_index('id')\n",
    "\n",
    "scoring=pd.DataFrame(index = [e['model_ident'] for e in embedders], columns=classifiers)\n",
    "\n",
    "for embedder in embedders:\n",
    "    embeddings = pd.read_pickle(f\"created_data/embeddings/{embedder['model_ident']}.pkl\")\n",
    "    X_val = embeddings.loc[y_val.index]\n",
    "\n",
    "    for classifier in classifiers:\n",
    "\n",
    "        classifier_models = {}\n",
    "        for annotator in annotators:\n",
    "            with open(f\"models/{embedder['model_ident']}_{classifier}_{annotator}.pkl\", 'rb') as f:\n",
    "                model = pickle.load(f)\n",
    "            classifier_models[annotator] = model\n",
    "\n",
    "        pred = pd.DataFrame(index=X_val.index, columns=annotators)\n",
    "\n",
    "        for idx, row in X_val.iterrows():\n",
    "            correct_annos = y_val.loc[idx].dropna().index\n",
    "            for anno in correct_annos:\n",
    "                pred[anno].loc[idx] = classifier_models[anno].predict([row['Embedding']])[0]\n",
    "\n",
    "        output_correct = output_st1(y_val)\n",
    "        output_predicted = output_st1(pred)\n",
    "\n",
    "        col_scorings = []\n",
    "        for col in output_correct.columns:\n",
    "            col_scorings.append(f1_score(output_correct[col], output_predicted[col], average='macro'))\n",
    "        print(f\"{embedder['model_ident']}-{classifier}: {col_scorings}\")\n",
    "        scoring.loc[embedder['model_ident']][classifier] = sum(col_scorings) / len(col_scorings)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "864bd60b8865555f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "scoring.plot(kind=\"bar\")\n",
    "plt.show()\n",
    "scoring"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8017f501c89cc166",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
