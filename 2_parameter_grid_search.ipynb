{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4914ad1e-766c-42de-a921-ab48aed369c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T19:47:31.529831Z",
     "start_time": "2024-07-20T19:47:31.521481Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e8e16fa-bb7a-4827-acb4-5c516203c87f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T19:47:31.536477Z",
     "start_time": "2024-07-20T19:47:31.531824Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8d5c3cb4-5baf-404a-89b7-ce1c4552f90f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T19:47:31.541840Z",
     "start_time": "2024-07-20T19:47:31.537613Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch version: 2.2.2\n",
      "cuda available: False\n",
      "devices count: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"pytorch version: {torch.__version__}\")\n",
    "print(f\"cuda available: {torch.cuda.is_available()}\")\n",
    "print(f\"devices count: {torch.cuda.device_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af2559ac-5aea-4f76-bd10-7f08794c76d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T19:47:31.561456Z",
     "start_time": "2024-07-20T19:47:31.543968Z"
    }
   },
   "outputs": [],
   "source": [
    "#Needed for MLP\n",
    "def balance_dataset(X, y): \n",
    "    value_counts = []\n",
    "    for i in range(5):\n",
    "        value_counts.append(y.count(i))\n",
    "    index = 0\n",
    "    added = {1: 0, 2: 0, 3: 0, 4: 0}\n",
    "    add_to_y = {1: [], 2: [], 3: [], 4: []}\n",
    "    add_to_X = {1: [], 2: [], 3: [], 4: []}\n",
    "    while sum(added.values()) + sum(value_counts) < 5 * value_counts[0]:\n",
    "        if index >= len(y):\n",
    "            index = 0\n",
    "        if y[index] != 0 and added[y[index]] + value_counts[y[index]] < value_counts[0]:\n",
    "            add_to_y[y[index]].append(y[index])\n",
    "            add_to_X[y[index]].append(X[index])\n",
    "            added[y[index]] += 1\n",
    "        index += 1\n",
    "    new_X = X.copy()\n",
    "    new_y = y.copy()\n",
    "    index = 0\n",
    "    while index < sum(added.values()):\n",
    "        for i in range(1, 5):\n",
    "            if len(add_to_y[i]) > 0:\n",
    "                new_y.append(add_to_y[i].pop(0))\n",
    "                new_X.append(add_to_X[i].pop(0))\n",
    "                index += 1\n",
    "    return new_X, new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d63ebfad-0336-43e6-ba71-fdf81c3e9082",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T19:47:31.566391Z",
     "start_time": "2024-07-20T19:47:31.562447Z"
    }
   },
   "outputs": [],
   "source": [
    "def embedJsonLInputFile(model, path):\n",
    "    input = pd.read_json(path, lines=True).set_index('id')\n",
    "    e = pd.DataFrame(index=input.index, columns=['Embedding'])\n",
    "    for idx in tqdm(input.index):\n",
    "        sentence = input.loc[idx]['text']\n",
    "        e.loc[idx]['Embedding'] = model.encode(sentence)\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "856cd7d2-2205-4522-96b3-1ab06c9188e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T19:47:31.575197Z",
     "start_time": "2024-07-20T19:47:31.567332Z"
    }
   },
   "outputs": [],
   "source": [
    "def output_st1(predictions):\n",
    "    #list with columns [\"id\": ..., \"A001\": \"1.0, \"A002\": 0.0, \"A003\": ..., ..., \"A012\": ...] \n",
    "    QUANT_TO_QUAL={0: 0, 1: 1, 2: 1, 3: 1, 4: 1}\n",
    "    NUMBER_TO_LABEL={0: \"0-Kein\", 1: \"1-Gering\", 2: \"2-Vorhanden\", 3: \"3-Stark\", 4: \"4-Extrem\"}\n",
    "    \n",
    "    #predictions_quant: pd.DataFrame = predictions.applymap(lambda x: LABEL_VALS_QUANT[x] if not pd.isna(x) else x)\n",
    "    predictions_qual: pd.DataFrame = predictions.applymap(lambda x: QUANT_TO_QUAL[x] if not pd.isna(x) else x)\n",
    "    \n",
    "    output = pd.DataFrame(index=[\"id\"])\n",
    "    output.index = predictions.index\n",
    "    \n",
    "    #create expected columns\n",
    "    output[\"bin_maj\"] = predictions_qual.mode(axis='columns')[0]\n",
    "    output[\"bin_one\"] = predictions_qual.apply(lambda x: (x == 1).any(), axis='columns')\n",
    "    output[\"bin_all\"] = predictions_qual.apply(lambda x: not (x == 0).any(), axis='columns')\n",
    "    output[\"multi_maj\"] = predictions.mode(axis='columns')[0].apply(lambda x: NUMBER_TO_LABEL[x])\n",
    "    output[\"disagree_bin\"] = output.apply(lambda x: x[\"bin_one\"] and not x[\"bin_all\"], axis='columns')\n",
    "    \n",
    "    #convert False/True to 0/1\n",
    "    output['bin_maj'] = output['bin_maj'].apply(lambda x: 1 if x else 0)\n",
    "    output['bin_one'] = output['bin_one'].apply(lambda x: 1 if x else 0)\n",
    "    output['bin_all'] = output['bin_all'].apply(lambda x: 1 if x else 0)\n",
    "    output['disagree_bin'] = output['disagree_bin'].apply(lambda x: 1 if x else 0)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5e04453c-a67a-4bad-ba49-02d4efc7fc2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T19:47:31.584507Z",
     "start_time": "2024-07-20T19:47:31.576677Z"
    }
   },
   "outputs": [],
   "source": [
    "embedders = [\n",
    "    {'model': 'intfloat/multilingual-e5-base', 'model_ident': 'me5-base'},\n",
    "    {'model': 'intfloat/multilingual-e5-large', 'model_ident': 'me5-large'},\n",
    "    {'model': 'deutsche-telekom/gbert-large-paraphrase-cosine', 'model_ident': 't-gbert-lpc'}\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    {\n",
    "        'model': SVC(kernel='rbf', C=5, class_weight=\"balanced\", random_state=SEED), \n",
    "        'model_ident': 'svc', \n",
    "        'prerun': None,\n",
    "        'param_grid': {'C': [1, 2, 5, 8, 13, 21, 35, 56, 91]}\n",
    "    }, {\n",
    "        'model': RandomForestClassifier(class_weight=\"balanced\", criterion=\"gini\", random_state=SEED), \n",
    "        'model_ident': 'rfc', \n",
    "        'prerun': None,\n",
    "        'param_grid': {'max_depth': [1, 2, 5, 8, 13, 21, 35, 56, 91], 'n_estimators': [10, 20, 50, 80, 130, 210, 350, 560]}\n",
    "    }, {\n",
    "        'model': MLPClassifier(early_stopping=True, n_iter_no_change=10, random_state=SEED, max_iter=1000), \n",
    "        'model_ident': 'mlp', \n",
    "        'prerun': balance_dataset,\n",
    "        'param_grid': {'hidden_layer_sizes': [(64,), (128,), (256,), (512,), (1024,), (1536,), (2048,)]}\n",
    "    }\n",
    "]\n",
    "\n",
    "annotators = [\"A001\", \"A002\", \"A003\", \"A004\", \"A005\", \"A007\", \"A008\", \"A009\", \"A010\", \"A012\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "26798741-0cc6-4148-96eb-2661d2886f7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T20:00:34.247049Z",
     "start_time": "2024-07-20T19:51:33.817275Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Model: me5-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5998/5998 [03:14<00:00, 30.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Model: svc\n",
      "Annotator: A001\n",
      "{'C': 21}\n",
      "0.6208791208791209\n",
      "Annotator: A002\n",
      "{'C': 91}\n",
      "0.7016666666666667\n",
      "Annotator: A003\n",
      "{'C': 2}\n",
      "0.5703125\n",
      "Annotator: A004\n",
      "{'C': 56}\n",
      "0.5934065934065934\n",
      "Annotator: A005\n",
      "{'C': 35}\n",
      "0.57\n",
      "Annotator: A007\n",
      "{'C': 56}\n",
      "0.6239316239316239\n",
      "Annotator: A008\n",
      "{'C': 91}\n",
      "0.7408376963350786\n",
      "Annotator: A009\n",
      "{'C': 56}\n",
      "0.6104347826086957\n",
      "Annotator: A010\n",
      "{'C': 91}\n",
      "0.6316666666666667\n",
      "Annotator: A012\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[33], line 65\u001B[0m\n\u001B[1;32m     62\u001B[0m X_val_list \u001B[38;5;241m=\u001B[39m X_val[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEmbedding\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mto_list()\n\u001B[1;32m     63\u001B[0m y_val_list \u001B[38;5;241m=\u001B[39m y_val[annotator]\u001B[38;5;241m.\u001B[39mto_list()\n\u001B[0;32m---> 65\u001B[0m \u001B[43mclf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train_list\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train_list\u001B[49m\u001B[43m)\u001B[49m    \n\u001B[1;32m     66\u001B[0m \u001B[38;5;28mprint\u001B[39m(clf\u001B[38;5;241m.\u001B[39mbest_params_)\n\u001B[1;32m     67\u001B[0m score \u001B[38;5;241m=\u001B[39m clf\u001B[38;5;241m.\u001B[39mscore(X_val_list, y_val_list)\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/germeval2024-pTWvK5q-/lib/python3.8/site-packages/sklearn/base.py:1152\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[0;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1145\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[1;32m   1147\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m   1148\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m   1149\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m   1150\u001B[0m     )\n\u001B[1;32m   1151\u001B[0m ):\n\u001B[0;32m-> 1152\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/germeval2024-pTWvK5q-/lib/python3.8/site-packages/sklearn/model_selection/_search.py:936\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[0;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[1;32m    934\u001B[0m refit_start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m    935\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 936\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbest_estimator_\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    937\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    938\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbest_estimator_\u001B[38;5;241m.\u001B[39mfit(X, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/germeval2024-pTWvK5q-/lib/python3.8/site-packages/sklearn/base.py:1152\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[0;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1145\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[1;32m   1147\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m   1148\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m   1149\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m   1150\u001B[0m     )\n\u001B[1;32m   1151\u001B[0m ):\n\u001B[0;32m-> 1152\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/germeval2024-pTWvK5q-/lib/python3.8/site-packages/sklearn/svm/_base.py:250\u001B[0m, in \u001B[0;36mBaseLibSVM.fit\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[1;32m    247\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[LibSVM]\u001B[39m\u001B[38;5;124m\"\u001B[39m, end\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    249\u001B[0m seed \u001B[38;5;241m=\u001B[39m rnd\u001B[38;5;241m.\u001B[39mrandint(np\u001B[38;5;241m.\u001B[39miinfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mi\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mmax)\n\u001B[0;32m--> 250\u001B[0m \u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msolver_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkernel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrandom_seed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mseed\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    251\u001B[0m \u001B[38;5;66;03m# see comment on the other call to np.iinfo in this file\u001B[39;00m\n\u001B[1;32m    253\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshape_fit_ \u001B[38;5;241m=\u001B[39m X\u001B[38;5;241m.\u001B[39mshape \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(X, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshape\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m (n_samples,)\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/germeval2024-pTWvK5q-/lib/python3.8/site-packages/sklearn/svm/_base.py:329\u001B[0m, in \u001B[0;36mBaseLibSVM._dense_fit\u001B[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001B[0m\n\u001B[1;32m    315\u001B[0m libsvm\u001B[38;5;241m.\u001B[39mset_verbosity_wrap(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose)\n\u001B[1;32m    317\u001B[0m \u001B[38;5;66;03m# we don't pass **self.get_params() to allow subclasses to\u001B[39;00m\n\u001B[1;32m    318\u001B[0m \u001B[38;5;66;03m# add other parameters to __init__\u001B[39;00m\n\u001B[1;32m    319\u001B[0m (\n\u001B[1;32m    320\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msupport_,\n\u001B[1;32m    321\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msupport_vectors_,\n\u001B[1;32m    322\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_support,\n\u001B[1;32m    323\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdual_coef_,\n\u001B[1;32m    324\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mintercept_,\n\u001B[1;32m    325\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_probA,\n\u001B[1;32m    326\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_probB,\n\u001B[1;32m    327\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfit_status_,\n\u001B[1;32m    328\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_iter,\n\u001B[0;32m--> 329\u001B[0m ) \u001B[38;5;241m=\u001B[39m \u001B[43mlibsvm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    330\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    331\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    332\u001B[0m \u001B[43m    \u001B[49m\u001B[43msvm_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msolver_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    333\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    334\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# TODO(1.4): Replace \"_class_weight\" with \"class_weight_\"\u001B[39;49;00m\n\u001B[1;32m    335\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclass_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m_class_weight\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mempty\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    336\u001B[0m \u001B[43m    \u001B[49m\u001B[43mkernel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkernel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    337\u001B[0m \u001B[43m    \u001B[49m\u001B[43mC\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mC\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    338\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnu\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnu\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    339\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprobability\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprobability\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    340\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdegree\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdegree\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    341\u001B[0m \u001B[43m    \u001B[49m\u001B[43mshrinking\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshrinking\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    342\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtol\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtol\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    343\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcache_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcache_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    344\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcoef0\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcoef0\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    345\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgamma\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_gamma\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    346\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepsilon\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mepsilon\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    347\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_iter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_iter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    348\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrandom_seed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrandom_seed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    349\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    351\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_warn_from_fit_status()\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "annotator_model_scores = {}\n",
    "models = {}\n",
    "\n",
    "for embedder in embedders:\n",
    "    print(f\"Embedding Model: {embedder['model_ident']}\")\n",
    "\n",
    "    annotator_model_scores[embedder[\"model_ident\"]] = {}\n",
    "    models[embedder[\"model_ident\"]] = {}\n",
    "    \n",
    "    embeddings = 0\n",
    "    embedding_model = SentenceTransformer(embedder['model'])\n",
    "    \n",
    "    if os.path.isfile(f\"created_data/embeddings/{embedder['model_ident']}.pkl\"):\n",
    "        embeddings = pd.read_pickle(f\"created_data/embeddings/{embedder['model_ident']}.pkl\")\n",
    "    else:\n",
    "        embeddings = embedJsonLInputFile(embedding_model, 'created_data/training_data/X_all.jsonl')\n",
    "        embeddings.to_pickle(f\"created_data/embeddings/{embedder['model_ident']}.pkl\")\n",
    "\n",
    "    if not os.path.isfile(f\"created_data/embeddings/{embedder['model_ident']}_test.pkl\"):\n",
    "        embeddings_test = embedJsonLInputFile(embedding_model, 'created_data/training_data/X_test.jsonl')\n",
    "        embeddings_test.to_pickle(f\"created_data/embeddings/{embedder['model_ident']}_test.pkl\")\n",
    "\n",
    "    embedding_dim = len(embeddings.iloc[0])\n",
    "\n",
    "    for classifier in classifiers:\n",
    "        print(f\"Classification Model: {classifier['model_ident']}\")\n",
    "\n",
    "        annotator_model_scores[embedder['model_ident']][classifier['model_ident']] = {}\n",
    "        models[embedder['model_ident']][classifier['model_ident']] = {}\n",
    "\n",
    "        \n",
    "        for annotator in annotators:\n",
    "            score = 0\n",
    "            print(f\"Annotator: {annotator}\")\n",
    "            \n",
    "            y_train = pd.read_json(f\"created_data/training_data/y_train_{annotator}.jsonl\", lines=True).set_index('id')\n",
    "            X_train = embeddings.loc[y_train.index]\n",
    "            \n",
    "            y_val = pd.read_json(f\"created_data/training_data/y_val_{annotator}.jsonl\", lines=True).set_index('id')\n",
    "            X_val = embeddings.loc[y_val.index]\n",
    "\n",
    "            models[embedder['model_ident']][classifier['model_ident']][annotator] = clone(classifier['model'])\n",
    "            classifier_model = models[embedder['model_ident']][classifier['model_ident']][annotator]\n",
    "\n",
    "            cached = False\n",
    "            with open(f\"created_data/cache.txt\", 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                for line in lines:\n",
    "                    if line.strip() == f\"{embedder['model_ident']}_{classifier['model_ident']}_{annotator}\":\n",
    "                        cached = True\n",
    "                        break\n",
    "            f.close()\n",
    "            if not cached:\n",
    "                clf = GridSearchCV(classifier_model, classifier['param_grid'], n_jobs=100, cv=5, refit=True)\n",
    "                \n",
    "                X_train_list = X_train['Embedding'].to_list()\n",
    "                y_train_list = y_train[annotator].to_list()\n",
    "    \n",
    "                if classifier[\"prerun\"] is not None:\n",
    "                    X_train_list, y_train_list = classifier[\"prerun\"](X_train_list, y_train_list)\n",
    "    \n",
    "                X_val_list = X_val['Embedding'].to_list()\n",
    "                y_val_list = y_val[annotator].to_list()\n",
    "    \n",
    "                clf.fit(X_train_list, y_train_list)    \n",
    "                print(clf.best_params_)\n",
    "                score = clf.score(X_val_list, y_val_list)\n",
    "\n",
    "                with open(f\"models/{embedder['model_ident']}_{classifier['model_ident']}_{annotator}.pkl\", 'w+b') as f:\n",
    "                    pickle.dump(clf.best_estimator_, f)\n",
    "                f.close()\n",
    "                with open(f\"created_data/cache.txt\", 'a') as f:\n",
    "                    f.write(f\"{embedder['model_ident']}-{classifier['model_ident']}-{annotator}\\n\")\n",
    "                f.close()    \n",
    "            else:\n",
    "                with open(f\"models/{embedder['model_ident']}_{classifier['model_ident']}_{annotator}.pkl\", 'rb') as f:\n",
    "                    cached_model = pickle.load(f)\n",
    "                f.close()    \n",
    "                print(f\"Cached: {cached_model}\")\n",
    "                score = cached_model.score(X_val_list, y_val_list)\n",
    "            \n",
    "            print(score)\n",
    "            annotator_model_scores[embedder['model_ident']][classifier['model_ident']][annotator] = score     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
